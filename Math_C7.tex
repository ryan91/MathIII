\chapter{Eigenwerte}

  \textbf{Problem:} $\alpha:V\rightarrow V$\\
  Gesucht: Basis $\mathcal{B}$  von $V$, so dass $A_\alpha^{\mathcal{B}}$ eine
  besonders einfache Gestalt hat.

  Besonders schön wäre: $A_\alpha^{\mathcal{B}}=
  \begin{pmatrix}
    a_1&\dots&0\\
    \vdots&\ddots&0\\
    0&\dots&a_n
  \end{pmatrix}$\\
  $\mathcal{B}=(v_1,...,v_n):\ \alpha(v_i)=a_iv_i$ geht nicht immer.

\section{Beispiel}
  \begin{enumerate}[a)]
    \item $\sigma:\ \mr^2\rightarrow\mr^2$ Spiegelung an $\lrg{e_1}$\\
      $\mathcal{B}=(e_1,e_2)$. $A_\sigma^{\mathcal{B}}=\lrv{1&0\\0&-1}$
    \item Derhung $\rho$ um $\sigma$ mit Winkel $\varphi\neq k\cdot\pi$
      ($k\in\mz$). Dann hat $A_\rho^{\mathcal{B}}$ für keine Basis
      ${\mathcal{B}}$ Diagonalgestalt.
  \end{enumerate}

\section{Definition: Eigenwert, Eigenvektor \& Eigenraum}
  $V$ K-VR, $\alpha:V\rightarrow V$ lineare Abbildung.\\
  $c\in K$ heißt \textbf{Eigenwert} von $\alpha$, falls $v\neq\sigma$ in $V$
  existiert mit $\alpha(v)=c\cdot v$\\
  Jedes solche $v\neq\sigma$ heißt \textbf{Eigenvektor} von $\alpha$ zum
  Eigenwert $c$.\\
  Die Menge aller Eigenvektoren zum Eigenvektor zusammen mit $\sigma$ heißt
  \textbf{Eigenraum} von $\alpha$ zum Eigenwert $c$.

\section{Bemerkung}
  $c$ heißt Eigenwert von $\alpha$, $\alpha:V\rightarrow V$ linear, Eigenraum
  von $\alpha$ zu $c=\mbox{ker}(c\cdot\id_V-\alpha)$, also Unterraum von $v$.\\
  Insbesondere: $0$ ist Eigenwert von
  $\alpha\Leftrightarrow\mbox{ker}(\alpha)\neq\lrr{0}$

  \textbf{Beweis:}\\
  $v\in$ Eigenraum von $\alpha$ zu $c$\\
  $\Leftrightarrow\alpha(v)=c\cdot v\Leftrightarrow c\cdot
  v-\alpha(v)=\sigma$\\
  $\Leftrightarrow(c\cdot\id_V-\alpha)(v)=\sigma$\\
  $\Leftrightarrow v\in\mbox{ker}(c\cdot\id_V-\alpha$).

\section{Beispiel}
  \begin{enumerate}[a)]
    \item $\id_V$ hat $1$ als Eigenwert, Eigenraum zu $1$ ist $V$.
    \item Spiegelung aus 7.1a)\\
      Eigenwert 1, Eigenraum zu $1=\lrg{e_1}$\\
      Eigenwert $-1$, Eigenraum zu $-1=\lrg{e_2}$
  \end{enumerate}

  Es gibt keine weiteren Eigenwerte.

\section{Definition}
  i $A$ $n\times n$- Matrix über Körper $K$.\\
  Eigenwerte von $A:=$Eigenwerte von $\alpha_A:\begin{cases}K^n\rightarrow
  K^n\\ x\mapsto A\cdot x\end{cases}$\\
  (d.h. $c\in K$ mit Eigenwert von $A\Leftrightarrow\exists 0\neq x\in K^n$ mit
  $A\cdot x=c\cdot x$).

\section{Satz: Eigenwerte von Abbildung und Darstellungsmatrix}
  $\alpha: V\rightarrow V$ lineare Abbildung. Dann haben $\alpha$ und
  $A_\alpha^{\mathcal{B}}$ die gleichen Eigenwerte für jede Basis ${\mathcal{B}}$.

  \textbf{Beweis:} Seien ${\mathcal{B}}$, $\mathcal{B}'$ Basen von $V$. S.20:
  Es existiert eine inverse Matrix $S(=S_{\mathcal{B},\mathcal{B}'})$ mit
  $A_\alpha^{\mathcal{B}'}=\ifu{S}\cdot A_\alpha^{\mathcal{B}}\cdot S$. Sei $c$
  Eigenwert von $A_\alpha^{\mathcal{B}}$, d.h. es existiert $0\neq x\in K^n$ mit
  $A_\alpha^{\mathcal{B}}\cdot x=c\cdot x$.\\
  $A_\alpha^{\mathcal{B}'}(\ifu{S}\cdot x)=\ifu(S)\cdot
  A_\alpha^{\mathcal{B}}\cdot S(\ifu{S}\cdot x)=\ifu{S}\cdot
  A_\alpha^{\mathcal{B}}\cdot x=\ifu{S}(c\cdot x)=c\cdot(\ifu{S}x)$\\
  Also $c$ ist Eigenwert von $A_\alpha^{\mathcal{B}'}$ (mit Eigenwert
  $\ifu{S}x)$.\\
  Umkehrung analog:\\
  Eigenwert von $A_\alpha^{\mathcal{B}}=$Eigenwert von $A_\alpha^{\mathcal{B}'}$.\\
  Sei $c$ Eigenwert von $\alpha$, $0\neq v$ Eigenvektor von $\alpha$ bezüglich
  $c$.\\
  $\alpha(v)=c\cdot v$\\
  $A_\alpha^{\mathcal{B}}\cdot
  K_{\mathcal{B}}(v)\ouset{=}{}{5.5}K_{\mathcal{B}}(\alpha(v))=K_{\mathcal{B}}(c\cdot
  v)=c\cdot K_b(v)$\\
  $c$ ist Eigenwert von $A_\alpha^{\mathcal{B}}$ (Eigenvektor
  $K_{\mathcal{B}}(v))$. Umkehrung analog.

\section{Satz}
  $V$ $n$- dim. K-VR, $\mathcal{B}$ Basis von $V$, $\alpha:V\rightarrow V$ linear,
  $A=A_\alpha^{\mathcal{B}}$, $c\in K.$\\
  Dann sind äquivalent:
  \begin{enumerate}[(1)]
    \item $c$ ist Eigenwert von $\alpha$
    \item $\mbox{ker}(c\cdot\id_V-\alpha)\neq\lrc{\sigma}$
    \item $\det(c\cdot E_n-A)=0$
  \end{enumerate}

  \textbf{Beweis:}\\
  (1)$\Leftrightarrow$(2). 7.3\\
  (2)$\Leftrightarrow$(3): $c\cdot E_n-A=A_{c\cdot\id_V-\alpha}^{\mathcal{B}}$\\
  $\det(c\cdot E_n-A)=0$\\
  $\ouset{\Leftrightarrow}{}{6.10} c\cdot E_n-A$ ist nicht ivertierbar.\\
  $\ouset{\Leftrightarrow}{}{4.16} c\cdot\id_V-\alpha$ ist nicht invertierbar.\\
  $\ouset{\Leftrightarrow}{}{4.8b)} c\cdot\id_V-\alpha$ ist nicht injektiv\\
  $\Leftrightarrow \mbox{ker}(c\cdot\id_v-\alpha)\neq\lrc{\sigma}$

  Bestimmung der Eigenwerte von $\alpha$, $A=A_\alpha^{\mathcal{B}}$. Suche alle $c\in
  K$ mit $\det(c\cdot E_n-A)=0$.\\
  Betrachte Funktion $f_A:\begin{cases}K\rightarrow K\\t\mapsto\det(t\cdot
  E_n-A)\end{cases}$

\section{Satz}
  Die Funkiton $f_A$ ist Polynomfunktion vom Grad $n$.\\
  $f_A(t)=\det(t\cdot E_n-A)=t^n+a_{n-1}t^{n-1}+...+a_1t+a_0$, $a_i\in K$
  (unabhängig von $t$)

  \textbf{Beweis:} Mit Entwicklungsformel

\section{Definition: Charakteristisches Polynom}
  \begin{enumerate}[a)]
    \item Das Polynom $\det(t\cdot E_n-A)\in K[t]$ heißt
      \textbf{charakteristisches Polynom} von $A\in M_n(K)$.
    \item $\alpha:V\rightarrow V$ linear, $\mathcal{B}$ Basis von $V$, so
      $\det(t\cdot\id_V-\alpha)=\det(t\cdot E_n-A)$, wobei
      $A=A_\alpha^{\mathcal{B}}$ (unabhängig von ${\mathcal{B}}$ nach 6.15)
      \textbf{charakteristisches Polynom} von $\alpha$.
  \end{enumerate}

\section{Korollar: Eigenschaften von Eigenwerten}
  $\alpha:V\rightarrow V$, $\dim(V)=n$
  \begin{enumerate}[a)]
    \item $c\in K$ ist Eigenwert von $\alpha$ $\Leftrightarrow$ $c$ ist
      Nullstelle des charakteristischen Polynoms von $\alpha$.
    \item $\alpha$ hat höchstens $n$ Eigenwerte. (Folgt aus 7.7 und 7.8)
  \end{enumerate}

\section{Beispiele}
  \begin{enumerate}[a)]
    \item $\alpha:\mr^2\rightarrow\mr^2$, $\mathcal{B}$ kanonische Basis.\\
      $A=A_\alpha^{\mathcal{B}}=\lrv{-1&2\\4&-3}$\\
      $\lrv{x\\y}\rightarrow\lrv{-1&2\\4&-3}\lrv{x\\y}=\lrv{-x+2y\\4x-3y}$\\
      $\det(tE_2-A)=\det\lrr{\lrv{t&0\\0&t}-\lrv{-1&2\\4&-3}}$\\
      $\det\lrv{+1&-2\\-4&t+3}=(t+1)(t+3)-8=\underbrace{t^2+4t-5}_{\mbox{\scriptsize
        char. Pol. von }\alpha}$\\
      $t^2+4t-5=0$, $t_{1,2}=-2\pm\sqrt{4+5}=1,-5$\\
      $\alpha$ hat Eigenwert $1,-5$

      Eigenvektoren zum Eigenwert 1\\
      $\alpha\lrv{x\\y}=\lrv{x\\y}$\\
      $\lrv{-x+2y\\4x-3y}=\lrv{x\\y}$\\
      $x=y\Leftrightarrow\begin{cases}-2x+2y=0\\4x-4y=0\end{cases}$\\
      Eigenraum zu Eigenvektor 1: $\lrc{\lrv{x\\x}:x\in\mr}=\lrg{\lrv{1\\1}}$

      Eigenvektoren zum Eigenwert 5\\
      $\alpha\lrv{x\\y}=-5\lrv{x\\y}$\\
      $\lrv{-x+2y\\4x-3y}=\lrv{-5x\\-5y}$\\
      $4y+2y=0\quad\Leftrightarrow\quad y=-2x$\\
      $4x+2y=0$\\
      Eigenraum zu Eigenvektor 2:\\
      $\lrc{\lrv{x\\-2x}:x\in\mr}=\lrg{\lrv{1\\-2}}$\\
      Wähle Basis ${\mathcal{B}}'=\lrc{\lrv{1\\1},\lrv{1\\-2}}$\\
      $A_\alpha^{\mathcal{B}'}=\lrv{1&0\\0&5}$
    \item $\rho:\mr^2\rightarrow\mr^2$ Drehung um $\frac{\pi}{2}$ um $0$, ${\mathcal{B}}$ kanonische Basis.\\
      $A=A_\alpha^{\mathcal{B}}=\lrv{\cos(\pi/2)&-\sin(\pi/2)\\\sin(\pi/2)&\cos(\pi/2)}=\lrv{0&-1\\1&0}$\\
      $\det(t\cdot E_2-A)=\det\lrv{t&1\\-1&t}=t^+1$.\\
      Kein Nullstellen in $\mr$, das heißt, $\rho$ hat keinen Eigenwert.
    \item Fasse $\rho$ aus b) als lineare Abbildung $\ouset{\rho}{\sim}{}:\mc^2\rightarrow\mc^2$ auf.\\
    	  $\ouset{\rho}{\sim}{}\lrv{x\\y}=\lrv{0&-1\\1&0}\lrv{x\\y}=\lrv{-y\\x}$\\
    	  $\Rightarrow$ charakteristisches Polynom $t^2+1$.\\
    	  $\ouset{\rho}{\sim}{}$ hat Eigenwerte $i,-i$.\\
    	  Eigenvektor zum Eigenwert $i$: $\ouset{\rho}{\sim}{}\lrv{x\\y}=\lrv{-y\\x}=i\lrv{x\\y}$\\
    	  $-y=ix,\lrr{x=iy}$\\
    	  Eigenraum zu $i$: $\lrc{\lrv{iy\\y}:y\in\mc}=\lrg{\lrv{i\\1}}_\mc$\\
    	  Eigenvektor zum Eigenwert $-i$: $\lrv{-y\\x}=-i\lrv{x\\y}$\\
    	  $-y=-ix$, $x=-iy$\\
    	  Eigenraum zu $-i$: $\lrc{\lrv{-iy\\y}:y\in\mc}=\lrg{\lrv{-i\\1}}_\mc$\\
    	  $\ouset{\mathcal{B}}{\sim}{}=\lrc{\lrv{i\\1},\lrv{-i\\1}}$ ist Basis von $\mc^2$\\
    	  $A_{\ouset{\rho}{\sim}{}}^{\ouset{\mathcal{B}}{\sim}{}}=\lrv{i&0\\0&-i}$  
  \end{enumerate}

\section{Satz: Eigenwerte von Dreiecksmatrizen}
	$\alpha:V\rightarrow V$ linear.\\
	Angenommen es existiert eine Basis $\mathcal{B}$ von $V$ mit $A_\alpha^\mathcal{B}=\lrv{a_{11}&*&*\\0&\ddots&*\\0&0&a_{nn}}$ (oder untere Dreiecksmatrix), so sind $a_{11},\dots,{a_nn}$ (Diagonalelemente) die Eigenwerte von $\alpha$ (mit Vielfachheit).

	\textbf{Beweis}

	$\det\lrr{tE_n-A_\alpha^{\mathcal{B}}}=\det\lrr{\lrv{t-a{11}&-*&-*\\0&\ddots&-*\\0&0&t-a_{nn}}}\ouset{=}{\smt{6.3b)}}{\smt{6.6}}\lrr{t-a_{11}}\cdot\dots\cdot\lrr{t-a_{nn}}$\\
	$\Rightarrow$ Behauptung

\section{Satz: lin. Unabhängigkeit von Eigenvektoren}
	Seien $c_1,\dots,c_r$ die paarweise verschiedenen Eigenwerte der linearen Abbildung $\alpha: V\rightarrow V$.\\
	$v_1,\dots,v_r$ Eigenvektoren zu $c_1,\dots,c_r$.\\
	Dann sind $v_1,\dots,v_r$ linear unabhängig.

	\textbf{Beweis}

	Induktion nach $r$:
	\begin{itemize}
		\item[IA] $r=1$: $v_1$ linear unabhängig, da $v_1\neq\sigma$
		\item[IV] $v_1,\dots,v_{r-1}$ linear unabhängig.
		\item[IS] Zeige: $v_1,\dots,v_r$ linear unabhängig\\
			Angenommen das wäre nicht so, dann\\
			$v_r=\limsum{i=1}{r-1}a_iv_i$ (nicht alle $a_i=0$, denn $v_r\neq\sigma$)\\
			$c_rv_r\alpha\lrr{v_r}=\alpha\lrr{\limsum{i=1}{r-1}a_iv_i}=\limsum{i=1}{r-1}a_i\alpha\lrr{v_i}=\limsum{i=1}{r-1}a_ic_iv_i$\\
			Andererseits:\\
			$c_rv_r\ouset{=}{}{*}\limsum{i=1}{r-1}a_ic_rv_i$\\
			$\limsum{i=1}{r-1}a_ic_iv_i=\limsum{i=1}{r-1}a_ic_rv_i$\\
			$\ouset{\Rightarrow}{v_1,\dots,v_{r-1}}{\smt{lin. unab.}}a_ic_i=a_ic_r\quad (i=1,\dots,r-1)$\\
			Existiert $j$ mit $a_j\neq 0 (j\in\lrc{q,\dots,r-1})$\\
			$a_jc_j=a_jc_r\Rightarrow c_j=c_r$\lightning
	\end{itemize}

\section{Definition: Diagonalisierbarkeit}
	$\alpha:V\rightarrow V$ linear. $\alpha$ heißt \textbf{diagonalisierbar}, falls $V$ eine Basis $\mathcal{B}$ aus Eigenvektroen von $V$ besitzt.\\
	$A_\alpha^\mathcal{B}=\lrv{c_{11}&0&0\\0&\ddots&0\\0&0&c_{nn}}$, $c_i\in K$ (nicht notwendig verschieden)

	$v\in V, v=\limsum{i=1}{n}a_iv_i\quad \alpha(v)=\limsum{i=1}{n}a_ic_iv_i$

\section{Satz: Diagonalisierbarkeit von Abbildungen}
	$\dim_K(v)=n$, $\alpha:V\rightarrow V$ linear.\\
	Besitzt $\alpha$ $n$ verschiedene Eigenwerte in $K$, dann ist $\alpha$ diagonalisierbar.

	\textbf{Beweis} Folgt aus 7.13

\section{Beispiel}
	$V$ ist 2-dimensional\\
	$A_\alpha^\mathcal{B}=\lrv{1&1\\0&1}$, dann ist das charakteristische Polinom $\det\lrr{\lrv{t-1&-1\\0&t-1}}=\lrr{t-1}^2$.\\
	Eigenwert $1$ mit Vielfachheit $2$\\
	$\alpha$ ist nicht diagonalisierbar, denn sonst gäbe es Basis $\mathcal{B}'$ mit $A_\alpha^{\mathcal{B}'}=\lrv{1&0\\0&1}$\\
	Dann ist $\alpha=\id_v$\lightning\\
	$\lrr{\mathcal{B}=\lrr{v_1,v_2},\alpha\lrr{v_2}=v_1+v_2}$

	Andererseits $\id_v$, $V$ $n$-dimensional\\
	Eigenwert $1$ mit Vielfachheit $n$\\
	$\id_V$ ist diagonalisierbar als $\lrv{1&0&0\\0&\ddots&0\\0&0&1}$\\
	$\Rightarrow$ Bedingung in 7.15 ist hinreichend, aber nicht notwendig!

\section{Bemerkung}
	$\alpha:V\rightarrow V$ linear, $\dim(V)=n$\\
	Besitzt $\alpha$ $n$ Eigenwerte (einschließlich Vielfachheit), das heißt $\det\lrr{tE_n-A}=\lrr{t-c_1}^{m_1}\cdot\dots\cdot\lrr{t-c_r}^{m_r}$, $m_1+\dots+m_r=n$ (Eigenwerte $c_1,\dots,c_r$)\\
	$V_i$ ist Eigenraum zu $c_i$\\
	Dann gilt $\dim\lrr{v_i}\leq m_i$\\
	Es gilt: $\alpha$ diagonalisierbar $\Leftrightarrow\dim\lrr{v_i}=m_i, i=1,\dots, r$\\
	In diesem Fall ist $\alpha$ diagonalisiert bezüglich Basis $\mathcal{B}$, die man als Vereinigung von Basen der $v_i$ bildet.

\section{Definition: Diagonalisierbarkeit Teil II}
	$A\in M_n(k)$ heißt \textbf{diagonalisierbar} falls $\alpha_A:\begin{cases}K^n\rightarrow K^n\\x\mapsto Ax\end{cases}$ diagonalisierbar ist.

\section{Satz: Diagonalisierbarkeit von Matrizen}
	\begin{enumerate}[a)]
		\item $A\in M_n(k)$ diagonalisierbar $\Leftrightarrow$ es existiert eine invertierbare Matrix $S\in M_n(k)$, so dass $S^{-1}AS$ die Diagonalmatrix ist.
		\item Hat $A$ $n$ verschiedene Eigenwerte, so ist $A$ diagonalisierbar
	\end{enumerate}
	\textbf{Beweis}
	\begin{enumerate}[a)]
		\item $\mathcal{B}$ ist kanonische Basis von $K^n$. $A=A_{\alpha_A}^{\mathcal{B}}$\\
			$A$ diagonalisierbar, so existiert Basis $\mathcal{B}'$ so dass $A_{\alpha_A}^{\mathcal{B}'}$ Diagonalmatrix.\\
			$S=S_{\mathcal{B},\mathcal{B}'}$\\
			$S^{-1}AS=S_{\mathcal{B}',\mathcal{B}}A_\alpha^\mathcal{B}S_{\mathcal{B},\mathcal{B'}}=A_\alpha^{\mathcal{B}'}$ Diagonalmatrix\\
			Umgekehrt beschreibt jede invertierbare Matrix den Wechsel von $\mathcal{B}$ zu anderer Basis.\\
			Daruas folgt die Behaubtung.
		\item Folgt aus 7.15
	\end{enumerate}
